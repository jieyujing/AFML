# 6. Exercises

6. Exercises
7. References
2. Chapter 3 Labeling
1. 3.1 Motivation
2. 3.2 The Fixed-Time Horizon Method
3. 3.3 Computing Dynamic Thresholds
4. 3.4 The Triple-Barrier Method
5. 3.5 Learning Side and Size
6. 3.6 Meta-Labeling
7. 3.7 How to Use Meta-Labeling
8. 3.8 The Quantamental Way
9. 3.9 Dropping Unnecessary Labels
10. Exercises
11. Bibliography
12. Note
3. Chapter 4 Sample Weights
1. 4.1 Motivation
2. 4.2 Overlapping Outcomes
3. 4.3 Number of Concurrent Labels
4. 4.4 Average Uniqueness of a Label
5. 4.5 Bagging Classifiers and Uniqueness
6. 4.6 Return Attribution
7. 4.7 Time Decay
8. 4.8 Class Weights
9. Exercises
10. References
11. Bibliography
4. Chapter 5 Fractionally Differentiated Features
1. 5.1 Motivation
2. 5.2 The Stationarity vs. Memory Dilemma
3. 5.3 Literature Review
4. 5.4 The Method
5. 5.5 Implementation
6. 5.6 Stationarity with Maximum Memory Preservation
7. 5.7 Conclusion
8. Exercises
9. References
10. Bibliography
4. PART 2 MODELLING
1. Chapter 6 Ensemble Methods
1.

---

5. 6.5 Boosting
6. 6.6 Bagging vs. Boosting in Finance
7. 6.7 Bagging for Scalability
8. Exercises
9. References
10. Bibliography
11. Notes
2. Chapter 7 Cross-Validation in Finance
1. 7.1 Motivation
2. 7.2 The Goal of Cross-Validation
3. 7.3 Why K-Fold CV Fails in Finance
4. 7.4 A Solution: Purged K-Fold CV
5. 7.5 Bugs in Sklearn's Cross-Validation
6. Exercises
7. Bibliography
3. Chapter 8 Feature Importance
1. 8.1 Motivation
2. 8.2 The Importance of Feature Importance
3. 8.3 Feature Importance with Substitution Effects
4. 8.4 Feature Importance without Substitution Effects
5. 8.5 Parallelized vs. Stacked Feature Importance
6. 8.6 Experiments with Synthetic Data
7. Exercises
8. References
9. Note
4. Chapter 9 Hyper-Parameter Tuning with Cross-Validation
1. 9.1 Motivation
2. 9.2 Grid Search Cross-Validation
3. 9.3 Randomized Search Cross-Validation
4. 9.4 Scoring and Hyper-parameter Tuning
5. Exercises
6. References
7. Bibliography
8. Notes
5. PART 3 BACKTESTING
1. Chapter 10 Bet Sizing

---

